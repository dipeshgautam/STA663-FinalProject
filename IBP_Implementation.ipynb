{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Infinite Latent Feature Models and the Indian Buffet Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indian Buffet Process (IBP)**\n",
    "\n",
    "The Indian Buffet is an adaptation of Chinese Buffett Process where each object instead of being associated with a single latent class can  be associated with multiple classes. This is particularly useful when each object has multile latent features and by associating objects with a single class we cannot partition them into homogeneous subsets.\n",
    "\n",
    "In the Indian buffet process, $N$ customers enter a restaurant one after another. Each customer encounters a buffet \n",
    "consisting of infinitely many dishes arranged in a line. The first customer starts at the left of the buffet and \n",
    "takes a serving from each dish, stopping after a Poisson($\\alpha$) number of dishes. The $i$th customer moves along the buffet, \n",
    "sampling dishes in proportion to their popularity, taking dish $k$ with probability $\\frac{m_k}{i}$ , where $m_k$ is the number of \n",
    "previous customers who have sampled that dish. Having reached the end of all previous sampled dishes, the $i$th customer \n",
    "then tries a Poisson($\\frac{\\alpha}{i}$) number of new dishes. Which costumer chose which dishes is indicated using a binary matrix **Z** with $N$ rows and infinitely many columns(corresponding to the infinitely many selection of dished), where $z_{ik}$ = 1 if the $i$th costumer sampled $k$th dish.\n",
    "\n",
    "IBP can be used as a prior in models for unsupervised learning. An example of which is presentd in the paper by Griffiths and Ghahramani, where IBP is used as a prior in linear-Gaussian binary latent feature model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gamma prior for $\\alpha$\n",
    "$$\n",
    "\\alpha \\sim Gamma(1,1)\n",
    "$$\n",
    "* Prior on **Z** is obtained by IBP as:\n",
    "$$\n",
    "P(z_{ik}=1|\\textbf{z}_{-i,k}) = \\frac{n_{-i,k}}{N}\n",
    "$$\n",
    "\n",
    "* Likelihood is given by\n",
    "\\begin{equation}\n",
    "P(X|Z,\\sigma_X, \\sigma_A) = \\frac{1}{(2 \\pi)^{ND/2} (\\sigma_X)^{(N-K)D}(\\sigma_A)^{KD}(|Z^TZ+\\frac{\\sigma_X^2}{\\sigma_A^2}I|)^{D/2}}exp\\{-\\frac{1}{2\\sigma_X^2}tr(X^T(I-Z(Z^TZ+\\frac{\\sigma_X^2}{\\sigma_A^2}I)^{-1}Z^T)X)\\}\n",
    "\\end{equation}\n",
    "\n",
    "After we have the likelihood and the prior given by IBP,\n",
    "\n",
    "* full conditional posterior for **Z** can be calculated as:\n",
    "$$\n",
    "P(z_{ik}|X,Z_{-(i,k)},\\sigma_X,\\sigma_A) \\propto  P(X|Z,\\sigma_X, \\sigma_A) * P(z_{ik}=1|\\textbf{z}_{-i,k}) \n",
    "$$\n",
    "\n",
    "To sample the number of new features for observation $i$, we use a truncated distribution, computing probabilities for a range of values $K_1^{(i)}$ up to an upper bound (say 4). The prior on number of features is given by $Poisson(\\frac{\\alpha}{N})$.\n",
    "Using this prior and the likelihood, we sample the nummber of new features.\n",
    "\n",
    "* Full conditional posterior for $\\alpha$ is given by:\n",
    "$$\n",
    "P(\\alpha|Z) \\sim Gamma(1+K_+,1+\\sum_{i=1}^{N} H_i)\n",
    "$$\n",
    "\n",
    "* For $\\sigma_X$ and $\\sigma_A$, we use MH algorithm as follows:\n",
    "\\begin{eqnarray}\n",
    "\\epsilon \\sim Uniform(-.05,.05)\\\\\n",
    "\\sigma_X^{*} =  \\sigma_X +\\epsilon\\\\\n",
    "\\end{eqnarray}\n",
    "Accept this new $\\sigma_X$ with probability given by:\n",
    "$$\n",
    "AR = min\\{1,\\frac{Likelihood(X|\\sigma_X^{*},...)}{Likelihood(X|\\sigma_X,...)}\\}\\\\\n",
    "$$\n",
    "Where AR is the acceptance ratio. We use similar algorithm to sample $\\sigma_A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo-code for a single iteration of Gibbs and MH combined algorigthm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "plt.style.use('ggplot')\n",
    "import Image\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "N = 100 #number of objects\n",
    "K = 4 #true number of features\n",
    "D = 36 # dimension of feature\n",
    "\n",
    "\n",
    "sigmaX0 = .5;\n",
    "A = np.array((0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n",
    "             0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \\\n",
    "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, \\\n",
    "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0)).reshape(4, D)\n",
    "\n",
    "\n",
    "I = (sigmaX0)*np.identity(D)\n",
    "Z0 = np.zeros((N, K))\n",
    "X = np.zeros((N, D))\n",
    "for i in range(N):\n",
    "    Z0[i,:] = (np.random.uniform(0,1,K) > .5).astype(int)\n",
    "    while (np.sum(Z0[i,:]) == 0):\n",
    "        Z0[i,:] = (np.random.uniform(0,1,K) > .5).astype(int)\n",
    "    #X[i,:] = np.random.multivariate_normal(Z0[i,:].dot(A), I)\n",
    "    #X(i,:) = randn(1, object_dim)*I+Z_orig(i,:)*A;\n",
    "    X[i,:] = np.random.normal(0,1, (1,D)).dot(I)+Z0[i,:].dot(A)\n",
    "# plt.figure(num=None, figsize=(12,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "# plt.subplot(141)\n",
    "# plt.pcolormesh(A[0,:].reshape(6,6),cmap=plt.cm.gray)     \n",
    "# plt.subplot(142)\n",
    "# plt.pcolormesh(A[1,:].reshape(6,6),cmap=plt.cm.gray)  \n",
    "# plt.subplot(143)\n",
    "# plt.pcolormesh(A[2,:].reshape(6,6),cmap=plt.cm.gray)  \n",
    "# plt.subplot(144)\n",
    "# plt.pcolormesh(A[3,:].reshape(6,6),cmap=plt.cm.gray) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Set initial numbers, dimensions and features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sample prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def sampleIBP(alpha, N):\n",
    "    result = np.zeros((N, 1000))\n",
    "    t = np.random.poisson(alpha)\n",
    "    if t>0:\n",
    "        result[0,0:t] = np.ones(t)\n",
    "    Kplus = t\n",
    "    for i in range(1,N):\n",
    "        for j in range(Kplus):\n",
    "            p = np.sum(result[0:i,j])/(i+1)\n",
    "            if np.random.uniform(0,1) < p:\n",
    "                result[i,j] = 1\n",
    "        t = np.random.poisson(alpha/(i+1))\n",
    "        if t>0:\n",
    "            result[i,Kplus:Kplus+t] = np.ones(t)\n",
    "            Kplus = Kplus+t\n",
    "    result = result[:,0:Kplus]\n",
    "    return np.array((result, Kplus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcInverse(Z,M,i,k,val):\n",
    "    M_i = M - M.dot(Z[i,:].T.dot(Z[i,:].dot(M)))/(Z[i,:].dot(M.dot(Z[i,:].T))-1)\n",
    "    #M_i = M-np.dot(np.dot(np.dot(M,Zn[i,:].T),Zn[i,:]),M)/(np.dot(np.dot(Zn[i,:],M),Zn[i,:].T)-1)\n",
    "    #Zn[i,k] = val\n",
    "    Z[i,k] = val\n",
    "    M = M_i - M_i.dot(Z[i,:].T.dot(Z[i,:].dot(M_i)))/(Z[i,:].dot(M_i.dot(Z[i,:].T))+1)\n",
    "    #M = M_i-np.dot(np.dot(np.dot(M_i,Zn[i,:].T),Zn[i,:]),M_i)/(np.dot(np.dot(Zn[i,:],M_i),Zn[i,:].T)+1)\n",
    "    Inv = M\n",
    "    return Inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a log likelihood function \n",
    "def ll(X, Z, sigmaX, sigmaA, K, D, N):\n",
    "    #M = Z[:,0:K].T.dot(Z[:,0:K])+sigmaX**2/sigmaA**2*np.identity(K)\n",
    "    M = Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K)\n",
    "    return (-1)*np.log(2*np.pi)*N*D*.5 - np.log(sigmaX)*(N-K)*D - np.log(sigmaA)*K*D - .5*D*np.log(np.linalg.det(M)) \\\n",
    "        -.5/(sigmaX**2)*np.trace( (X.T.dot( np.identity(N)-Z.dot(np.linalg.inv(M).dot(Z.T)) )).dot(X) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a log likelihood function \n",
    "def ll_m(X, Z, sigmaX, sigmaA, K, D, N, M):\n",
    "    M1 = Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K)\n",
    "    return (-1)*np.log(2*np.pi)*N*D*.5 - np.log(sigmaX)*(N-K)*D - np.log(sigmaA)*K*D - .5*D*np.log(np.linalg.det(M1)) \\\n",
    "        -.5/(sigmaX**2)*np.trace( (X.T.dot( np.identity(N)-Z.dot(M.dot(Z.T)) )).dot(X) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit ll(X, Z, sigmaX, sigmaA, Kplus , D, N)\n",
    "%timeit cy_ll(X, Z, sigmaX, sigmaA, Kplus , D, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HN = 0.\n",
    "for i in range(1,N+1):\n",
    "    HN += 1./i\n",
    "    \n",
    "#Kplus = 4 #current number of features with at least one object\n",
    "niter = 400\n",
    "sigmaX = 1.\n",
    "sigmaA = 1.\n",
    "alpha = 1.\n",
    "maxNew = 4\n",
    "BURN_IN=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE=niter-BURN_IN\n",
    "\n",
    "K_inf=20\n",
    "\n",
    "chain_Z=np.zeros((SAMPLE_SIZE,N,K_inf))\n",
    "chain_K=np.zeros((SAMPLE_SIZE,1))\n",
    "chain_sigma_X=np.zeros((SAMPLE_SIZE,1))\n",
    "chain_sigma_A=np.zeros((SAMPLE_SIZE,1))\n",
    "chain_alpha=np.zeros((SAMPLE_SIZE,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "np.random.seed(1)\n",
    "Z, Kplus = sampleIBP(alpha, N)\n",
    "s_counter=0\n",
    "\n",
    "for j in range(niter):\n",
    "    print(\"iteration:\",j ,  \"Kplus:\",Kplus,  \"shape of Z\", Z.shape, \"alpha:\", alpha, \"sigmaX\", sigmaX)\n",
    "    #update z\n",
    "    if((j+1)>BURN_IN):\n",
    "        chain_Z[s_counter,:,0:Kplus]=Z\n",
    "        chain_K[s_counter]=Kplus\n",
    "        chain_sigma_X[s_counter]=sigmaX\n",
    "        chain_sigma_A[s_counter]=sigmaA\n",
    "        chain_alpha[s_counter]=alpha\n",
    "        s_counter=s_counter+1\n",
    "    \n",
    "    for i in range(N):\n",
    "        M = np.linalg.inv(Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(Kplus))\n",
    "        for k in range(Kplus):\n",
    "            #print k\n",
    "            if k>=Kplus:\n",
    "                break     \n",
    "            #Removing the singular features, i.e. the ones that have 1 for the current object only.\n",
    "            if Z[i,k] > 0:\n",
    "                if (np.sum(Z[:,k])- 1) <=0:\n",
    "                    Z[i,k] = 0\n",
    "                    Z[:,k:(Kplus-1)] = Z[:,(k+1):Kplus] #shift everything one column to the left\n",
    "                    Kplus = Kplus-1\n",
    "                    Z = Z[:,0:Kplus] # remove the last column as it is redundent\n",
    "                    M = np.linalg.inv(Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(Kplus))\n",
    "                    continue #We're no longer looking at this feature, so move to another one               \n",
    "        \n",
    "            P = np.zeros(2)\n",
    "            \n",
    "            M0 = calcInverse(Z,M,i,k,0)\n",
    "            M1 = calcInverse(Z,M,i,k,1)\n",
    "            #set Z[i,k] = 0 and calculate posterior probability\n",
    "            Z[i,k] = 0\n",
    "            P[0] = ll_m(X, Z, sigmaX, sigmaA, Kplus, D, N, M0) + np.log(N-np.sum(Z[:,k])) - np.log(N)\n",
    "        \n",
    "            #set Z[i,k] = 1 and calculate posterior probability\n",
    "            Z[i,k] = 1\n",
    "            P[1] = ll_m(X, Z,sigmaX, sigmaA, Kplus, D, N, M1)  + np.log(np.sum(Z[:,k])- 1) - np.log(N)\n",
    "        \n",
    "            P = np.exp(P - max(P))\n",
    "            U = np.random.uniform(0,1)\n",
    "            if U<(P[1]/(np.sum(P))):\n",
    "                Z[i,k] = 1\n",
    "                M = M1\n",
    "            else:\n",
    "                Z[i,k] = 0  \n",
    "                M = M0\n",
    "    \n",
    "    \n",
    "        #Sample number of new features\n",
    "        prob = np.zeros(maxNew)\n",
    "        alphaN = alpha/N\n",
    "        for kNew in range(maxNew): # max new features is 3\n",
    "            Z_temp = Z\n",
    "            if kNew>0:\n",
    "                addCols = np.zeros((N,kNew))\n",
    "                addCols[i,:] = 1\n",
    "                Z_temp = np.hstack((Z_temp, addCols))\n",
    "            \n",
    "            pois = kNew*np.log(alphaN) - alphaN - np.log(math.factorial(kNew))\n",
    "            M = np.linalg.inv(Z_temp.T.dot(Z_temp)+(sigmaX**2/sigmaA**2)*np.identity(Kplus+kNew))\n",
    "            lik = ll_m(X = X, Z = Z_temp, sigmaX = sigmaX, sigmaA = sigmaA, K=(Kplus+kNew), D= D, N= N, M=M)\n",
    "            prob[kNew] = pois + lik\n",
    "\n",
    "        #normalize prob\n",
    "        prob = np.exp(prob - max(prob))\n",
    "        prob = prob/sum(prob)\n",
    "        \n",
    "        U = np.random.uniform(0,1,1)\n",
    "        p = 0\n",
    "        kNew=0\n",
    "        for new in range(maxNew):\n",
    "            p = p+prob[new]\n",
    "            if U<p:\n",
    "                kNew = new\n",
    "                break\n",
    "     \n",
    "        #Add kNew new columns to Z and set the values at ith row to 1 for all of them\n",
    "        if kNew>0:\n",
    "            addCols = np.zeros((N,kNew))\n",
    "            addCols[i,:] = 1\n",
    "            Z = np.hstack((Z, addCols))\n",
    "        Kplus = Kplus + kNew \n",
    "    \n",
    "    M = np.linalg.inv(Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(Kplus))\n",
    "    \n",
    "    llCurrent = ll_m(X, Z, sigmaX, sigmaA, Kplus, D, N, M )\n",
    "    #update sigmaX\n",
    "    if np.random.uniform(0,1) < .5:\n",
    "        sigmaX_new = sigmaX - np.random.uniform(0,1)/20\n",
    "    else:\n",
    "        sigmaX_new = sigmaX + np.random.uniform(0,1)/20\n",
    "    llNew = ll_m(X, Z, sigmaX_new, sigmaA, Kplus, D, N, M)\n",
    "\n",
    "    arX = np.exp(min(0,llNew-llCurrent))\n",
    "    U = np.random.uniform(0,1)\n",
    "    if U < arX:\n",
    "        sigmaX = sigmaX_new\n",
    "        \n",
    "        \n",
    "    #update sigma_A\n",
    "    #epsA = np.random.uniform(0,1)\n",
    "    if np.random.uniform(0,1) < .5:\n",
    "        sigmaA_new = sigmaA - np.random.uniform(0,1)/20\n",
    "    else:\n",
    "        sigmaA_new = sigmaA + np.random.uniform(0,1)/20\n",
    "    \n",
    "    \n",
    "#     epsA = np.random.uniform(-.05,.05)\n",
    "#     sigmaA_new = sigmaA+epsA\n",
    "    #llCurrent = ll(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "    #llCurrent = ll(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "    llNew = ll_m(X, Z, sigmaX, sigmaA_new, Kplus, D, N, M)\n",
    "\n",
    "    arA = np.exp(min(0,llNew-llCurrent))\n",
    "\n",
    "    U = np.random.uniform(0,1)\n",
    "    if U < arA:\n",
    "        sigmaA = sigmaA_new\n",
    "        \n",
    "    alpha = np.random.gamma(1+Kplus, 1/(1+HN))\n",
    "t1 = time.time()\n",
    "timeElapsed = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampler(X, niter, BURN_IN, sigmaX, sigmaA,alpha, N, D, maxNew):\n",
    "    HN = 0.\n",
    "    for i in range(1,N+1):\n",
    "        HN += 1./i\n",
    "\n",
    "    SAMPLE_SIZE=niter-BURN_IN\n",
    "\n",
    "    K_inf=20\n",
    "\n",
    "    chain_Z=np.zeros((SAMPLE_SIZE,N,K_inf))\n",
    "    chain_K=np.zeros((SAMPLE_SIZE,1))\n",
    "    chain_sigma_X=np.zeros((SAMPLE_SIZE,1))\n",
    "    chain_sigma_A=np.zeros((SAMPLE_SIZE,1))\n",
    "    chain_alpha=np.zeros((SAMPLE_SIZE,1))\n",
    "    np.random.seed(1)\n",
    "    Z, Kplus = sampleIBP(alpha, N)\n",
    "    s_counter=0\n",
    "\n",
    "    for j in range(niter):\n",
    "        if j%50==0:\n",
    "            print j\n",
    "        #print(\"iteration:\",j ,  \"Kplus:\",Kplus,  \"shape of Z\", Z.shape, \"alpha:\", alpha, \"sigmaX\", sigmaX)\n",
    "        #update z\n",
    "        if((j+1)>BURN_IN):\n",
    "            chain_Z[s_counter,:,0:Kplus]=Z\n",
    "            chain_K[s_counter]=Kplus\n",
    "            chain_sigma_X[s_counter]=sigmaX\n",
    "            chain_sigma_A[s_counter]=sigmaA\n",
    "            chain_alpha[s_counter]=alpha\n",
    "            s_counter=s_counter+1\n",
    "\n",
    "        for i in range(N):\n",
    "            for k in range(Kplus):\n",
    "                #print k\n",
    "                if k>=Kplus:\n",
    "                    break     \n",
    "                #Removing the singular features, i.e. the ones that have 1 for the current object only.\n",
    "                if Z[i,k] > 0:\n",
    "                    if (np.sum(Z[:,k])- 1) <=0:\n",
    "                        #Z[i,k] = 0\n",
    "                        Z[:,k:(Kplus-1)] = Z[:,(k+1):Kplus] #shift everything one column to the left\n",
    "                        Kplus = Kplus-1\n",
    "                        Z = Z[:,0:Kplus] # remove the last column as it is redundent\n",
    "                        continue #We're no longer looking at this feature, so move to another one               \n",
    "\n",
    "                P = np.zeros(2)\n",
    "                #set Z[i,k] = 0 and calculate posterior probability\n",
    "                Z[i,k] = 0\n",
    "                P[0] = ll(X, Z, sigmaX, sigmaA, Kplus, D, N) + np.log(N-np.sum(Z[:,k])) - np.log(N)\n",
    "\n",
    "                #set Z[i,k] = 1 and calculate posterior probability\n",
    "                Z[i,k] = 1\n",
    "                P[1] = ll(X, Z,sigmaX, sigmaA, Kplus, D, N)  + np.log(np.sum(Z[:,k])- 1) - np.log(N)\n",
    "\n",
    "                P = np.exp(P - max(P))\n",
    "                U = np.random.uniform(0,1)\n",
    "                if U<(P[1]/(np.sum(P))):\n",
    "                    Z[i,k] = 1\n",
    "                else:\n",
    "                    Z[i,k] = 0   \n",
    "\n",
    "\n",
    "            #Sample number of new features\n",
    "            prob = np.zeros(maxNew)\n",
    "            alphaN = alpha/N\n",
    "            for kNew in range(maxNew): # max new features is 3\n",
    "                Z_temp = Z\n",
    "                if kNew>0:\n",
    "                    addCols = np.zeros((N,kNew))\n",
    "                    addCols[i,:] = 1\n",
    "                    Z_temp = np.hstack((Z_temp, addCols))\n",
    "\n",
    "                pois = kNew*np.log(alphaN) - alphaN - np.log(math.factorial(kNew))\n",
    "                lik = ll(X = X, Z = Z_temp, sigmaX = sigmaX, sigmaA = sigmaA, K=(Kplus+kNew), D= D, N= N)\n",
    "                prob[kNew] = pois + lik\n",
    "\n",
    "            #normalize prob\n",
    "            prob = np.exp(prob - max(prob))\n",
    "            prob = prob/sum(prob)\n",
    "\n",
    "            U = np.random.uniform(0,1,1)\n",
    "            p = 0\n",
    "            kNew=0\n",
    "            for new in range(maxNew):\n",
    "                p = p+prob[new]\n",
    "                if U<p:\n",
    "                    kNew = new\n",
    "                    break\n",
    "\n",
    "            #Add kNew new columns to Z and set the values at ith row to 1 for all of them\n",
    "            if kNew>0:\n",
    "                addCols = np.zeros((N,kNew))\n",
    "                addCols[i,:] = 1\n",
    "                Z = np.hstack((Z, addCols))\n",
    "            Kplus = Kplus + kNew \n",
    "\n",
    "        llCurrent = ll(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "        #update sigmaX\n",
    "        if np.random.uniform(0,1) < .5:\n",
    "            sigmaX_new = sigmaX - np.random.uniform(0,1)/20\n",
    "        else:\n",
    "            sigmaX_new = sigmaX + np.random.uniform(0,1)/20\n",
    "        llNew = ll(X, Z, sigmaX_new, sigmaA, Kplus, D, N)\n",
    "\n",
    "        arX = np.exp(min(0,llNew-llCurrent))\n",
    "        U = np.random.uniform(0,1)\n",
    "        if U < arX:\n",
    "            sigmaX = sigmaX_new\n",
    "\n",
    "\n",
    "        #update sigma_A\n",
    "        #epsA = np.random.uniform(0,1)\n",
    "        if np.random.uniform(0,1) < .5:\n",
    "            sigmaA_new = sigmaA - np.random.uniform(0,1)/20\n",
    "        else:\n",
    "            sigmaA_new = sigmaA + np.random.uniform(0,1)/20\n",
    "\n",
    "\n",
    "    #     epsA = np.random.uniform(-.05,.05)\n",
    "    #     sigmaA_new = sigmaA+epsA\n",
    "        #llCurrent = ll(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "        #llCurrent = ll(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "        llNew = ll(X, Z, sigmaX, sigmaA_new, Kplus, D, N)\n",
    "\n",
    "        arA = np.exp(min(0,llNew-llCurrent))\n",
    "\n",
    "        U = np.random.uniform(0,1)\n",
    "        if U < arA:\n",
    "            sigmaA = sigmaA_new\n",
    "\n",
    "        alpha = np.random.gamma(1+Kplus, 1/(1+HN))\n",
    "    \n",
    "    return(chain_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HN = 0.\n",
    "for i in range(1,N+1):\n",
    "    HN += 1./i\n",
    "    \n",
    "#Kplus = 4 #current number of features with at least one object\n",
    "niter = 400\n",
    "sigmaX = 1.\n",
    "sigmaA = 1.\n",
    "alpha = 1.\n",
    "maxNew = 4\n",
    "BURN_IN=200\n",
    "t0 = time.time()\n",
    "#sampler(X, niter, BURN_IN, sigmaX, sigmaA,alpha, N, D, maxNew)\n",
    "t1= time.time()\n",
    "\n",
    "dt = t1-t0\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Cython_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%file Cython_setup.py\n",
    "from distutils.core import setup\n",
    "from Cython.Build import cythonize\n",
    "\n",
    "setup(\n",
    "    ext_modules = cythonize(\"Cython_functions.pyx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Cython_functions.pyx\n"
     ]
    }
   ],
   "source": [
    "%%file Cython_functions.pyx\n",
    "import numpy as np\n",
    "\n",
    "def ll(X, Z, sigmaX, sigmaA, K, D, N):\n",
    "    #M = Z[:,0:K].T.dot(Z[:,0:K])+sigmaX**2/sigmaA**2*np.identity(K)\n",
    "    M = Z.T.dot(Z)+(sigmaX**2/sigmaA**2)*np.identity(K)\n",
    "    return (-1)*np.log(2*np.pi)*N*D*.5 - np.log(sigmaX)*(N-K)*D - np.log(sigmaA)*K*D - .5*D*np.log(np.linalg.det(M)) \\\n",
    "        -.5/(sigmaX**2)*np.trace( (X.T.dot( np.identity(N)-Z.dot(np.linalg.inv(M).dot(Z.T)) )).dot(X) )\n",
    "\n",
    "np.random.seed(1)\n",
    "def sampleIBP(alpha, N):\n",
    "    result = np.zeros((N, 1000))\n",
    "    t = np.random.poisson(alpha)\n",
    "    if t>0:\n",
    "        result[0,0:t] = np.ones(t)\n",
    "    Kplus = t\n",
    "    for i in range(1,N):\n",
    "        for j in range(Kplus):\n",
    "            p = np.sum(result[0:i,j])/(i+1)\n",
    "            if np.random.uniform(0,1) < p:\n",
    "                result[i,j] = 1\n",
    "        t = np.random.poisson(alpha/(i+1))\n",
    "        if t>0:\n",
    "            result[i,Kplus:Kplus+t] = np.ones(t)\n",
    "            Kplus = Kplus+t\n",
    "    result = result[:,0:Kplus]\n",
    "    return np.array((result, Kplus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Cython_functions.pyx because it changed.\n",
      "Cythonizing Cython_functions.pyx\n",
      "running build_ext\n",
      "building 'Cython_functions' extension\n",
      "gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/bitnami/anaconda/include/python2.7 -c Cython_functions.c -o build/temp.linux-x86_64-2.7/Cython_functions.o\n",
      "gcc -pthread -shared build/temp.linux-x86_64-2.7/Cython_functions.o -L/home/bitnami/anaconda/lib -lpython2.7 -o /home/bitnami/STA663-FinalProject/Cython_functions.so\n"
     ]
    }
   ],
   "source": [
    "! python Cython_setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%cython -a\n",
    "import numpy as np\n",
    "#cimport numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import Cython_functions as func\n",
    "\n",
    "def sampler_cy(X, niter, BURN_IN, sigmaX, sigmaA,alpha, N, D, maxNew):\n",
    "    HN = 0.\n",
    "    for i in range(1,N+1):\n",
    "        HN += 1./i\n",
    "\n",
    "    SAMPLE_SIZE=niter-BURN_IN\n",
    "\n",
    "    K_inf=20\n",
    "\n",
    "    chain_Z=np.zeros((SAMPLE_SIZE,N,K_inf))\n",
    "    chain_K=np.zeros((SAMPLE_SIZE,1))\n",
    "    chain_sigma_X=np.zeros((SAMPLE_SIZE,1))\n",
    "    chain_sigma_A=np.zeros((SAMPLE_SIZE,1))\n",
    "    chain_alpha=np.zeros((SAMPLE_SIZE,1))\n",
    "    np.random.seed(1)\n",
    "    Z, Kplus = func.sampleIBP(alpha, N)\n",
    "    s_counter=0\n",
    "\n",
    "    for j in range(niter):\n",
    "        if j%50==0:\n",
    "            print j\n",
    "        #print(\"iteration:\",j ,  \"Kplus:\",Kplus,  \"shape of Z\", Z.shape, \"alpha:\", alpha, \"sigmaX\", sigmaX)\n",
    "        #update z\n",
    "        if((j+1)>BURN_IN):\n",
    "            chain_Z[s_counter,:,0:Kplus]=Z\n",
    "            chain_K[s_counter]=Kplus\n",
    "            chain_sigma_X[s_counter]=sigmaX\n",
    "            chain_sigma_A[s_counter]=sigmaA\n",
    "            chain_alpha[s_counter]=alpha\n",
    "            s_counter=s_counter+1\n",
    "\n",
    "        for i in range(N):\n",
    "            for k in range(Kplus):\n",
    "                #print k\n",
    "                if k>=Kplus:\n",
    "                    break     \n",
    "                #Removing the singular features, i.e. the ones that have 1 for the current object only.\n",
    "                if Z[i,k] > 0:\n",
    "                    if (np.sum(Z[:,k])- 1) <=0:\n",
    "                        #Z[i,k] = 0\n",
    "                        Z[:,k:(Kplus-1)] = Z[:,(k+1):Kplus] #shift everything one column to the left\n",
    "                        Kplus = Kplus-1\n",
    "                        Z = Z[:,0:Kplus] # remove the last column as it is redundent\n",
    "                        continue #We're no longer looking at this feature, so move to another one               \n",
    "\n",
    "                P = np.zeros(2)\n",
    "                #set Z[i,k] = 0 and calculate posterior probability\n",
    "                Z[i,k] = 0\n",
    "                P[0] = func.ll(X, Z, sigmaX, sigmaA, Kplus, D, N) + np.log(N-np.sum(Z[:,k])) - np.log(N)\n",
    "\n",
    "                #set Z[i,k] = 1 and calculate posterior probability\n",
    "                Z[i,k] = 1\n",
    "                P[1] = func.ll(X, Z,sigmaX, sigmaA, Kplus, D, N)  + np.log(np.sum(Z[:,k])- 1) - np.log(N)\n",
    "\n",
    "                P = np.exp(P - max(P))\n",
    "                U = np.random.uniform(0,1)\n",
    "                if U<(P[1]/(np.sum(P))):\n",
    "                    Z[i,k] = 1\n",
    "                else:\n",
    "                    Z[i,k] = 0   \n",
    "\n",
    "\n",
    "            #Sample number of new features\n",
    "            prob = np.zeros(maxNew)\n",
    "            alphaN = alpha/N\n",
    "            for kNew in range(maxNew): # max new features is 3\n",
    "                Z_temp = Z\n",
    "                if kNew>0:\n",
    "                    addCols = np.zeros((N,kNew))\n",
    "                    addCols[i,:] = 1\n",
    "                    Z_temp = np.hstack((Z_temp, addCols))\n",
    "\n",
    "                pois = kNew*np.log(alphaN) - alphaN - np.log(math.factorial(kNew))\n",
    "                lik = func.ll(X = X, Z = Z_temp, sigmaX = sigmaX, sigmaA = sigmaA, K=(Kplus+kNew), D= D, N= N)\n",
    "                prob[kNew] = pois + lik\n",
    "\n",
    "            #normalize prob\n",
    "            prob = np.exp(prob - max(prob))\n",
    "            prob = prob/sum(prob)\n",
    "\n",
    "            U = np.random.uniform(0,1,1)\n",
    "            p = 0\n",
    "            kNew=0\n",
    "            for new in range(maxNew):\n",
    "                p = p+prob[new]\n",
    "                if U<p:\n",
    "                    kNew = new\n",
    "                    break\n",
    "\n",
    "            #Add kNew new columns to Z and set the values at ith row to 1 for all of them\n",
    "            if kNew>0:\n",
    "                addCols = np.zeros((N,kNew))\n",
    "                addCols[i,:] = 1\n",
    "                Z = np.hstack((Z, addCols))\n",
    "            Kplus = Kplus + kNew \n",
    "\n",
    "        llCurrent = func.ll(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "        #update sigmaX\n",
    "        if np.random.uniform(0,1) < .5:\n",
    "            sigmaX_new = sigmaX - np.random.uniform(0,1)/20\n",
    "        else:\n",
    "            sigmaX_new = sigmaX + np.random.uniform(0,1)/20\n",
    "        llNew = func.ll(X, Z, sigmaX_new, sigmaA, Kplus, D, N)\n",
    "\n",
    "        arX = np.exp(min(0,llNew-llCurrent))\n",
    "        U = np.random.uniform(0,1)\n",
    "        if U < arX:\n",
    "            sigmaX = sigmaX_new\n",
    "\n",
    "\n",
    "        #update sigma_A\n",
    "        #epsA = np.random.uniform(0,1)\n",
    "        if np.random.uniform(0,1) < .5:\n",
    "            sigmaA_new = sigmaA - np.random.uniform(0,1)/20\n",
    "        else:\n",
    "            sigmaA_new = sigmaA + np.random.uniform(0,1)/20\n",
    "\n",
    "\n",
    "    #     epsA = np.random.uniform(-.05,.05)\n",
    "    #     sigmaA_new = sigmaA+epsA\n",
    "        #llCurrent = ll(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "        #llCurrent = ll(X, Z, sigmaX, sigmaA, Kplus, D, N )\n",
    "        llNew = func.ll(X, Z, sigmaX, sigmaA_new, Kplus, D, N)\n",
    "\n",
    "        arA = np.exp(min(0,llNew-llCurrent))\n",
    "\n",
    "        U = np.random.uniform(0,1)\n",
    "        if U < arA:\n",
    "            sigmaA = sigmaA_new\n",
    "\n",
    "        alpha = np.random.gamma(1+Kplus, 1/(1+HN))\n",
    "    \n",
    "    return(chain_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HN = 0.\n",
    "for i in range(1,N+1):\n",
    "    HN += 1./i\n",
    "    \n",
    "#Kplus = 4 #current number of features with at least one object\n",
    "niter = 400\n",
    "sigmaX = 1.\n",
    "sigmaA = 1.\n",
    "alpha = 1.\n",
    "maxNew = 4\n",
    "BURN_IN=200\n",
    "t0 = time.time()\n",
    "#sampler(X, niter, BURN_IN, sigmaX, sigmaA,alpha, N, D, maxNew)\n",
    "# t1= time.time()\n",
    "\n",
    "# dt = t1-t0\n",
    "# dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1 loops, best of 3: 8min 1s per loop\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1 loops, best of 3: 7min 52s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sampler_cy(X, 1000, 0, sigmaX, sigmaA,alpha, N, D, maxNew)\n",
    "%timeit sampler(X, 1000, 0, sigmaX, sigmaA,alpha, N, D, maxNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = %prun -r -q sampler(X, 30, 0, sigmaX, sigmaA,alpha, N, D, maxNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         19735386 function calls in 110.447 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 120 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  1500360   41.488    0.000   41.488    0.000 {method 'dot' of 'numpy.ndarray' objects}\n",
      "   300072   14.871    0.000   96.889    0.000 <ipython-input-4-b6095f8d1143>:2(ll)\n",
      "   300072    9.032    0.000   14.822    0.000 linalg.py:455(inv)\n",
      "        1    6.954    6.954  110.447  110.447 <ipython-input-19-2fbc1bc057f9>:1(sampler)\n",
      "   300072    6.007    0.000   11.067    0.000 linalg.py:1679(det)\n",
      "   600144    3.941    0.000    9.605    0.000 numeric.py:2125(identity)\n",
      "   600144    3.535    0.000    5.664    0.000 twodim_base.py:190(eye)\n",
      "   300072    3.293    0.000    3.293    0.000 {method 'trace' of 'numpy.ndarray' objects}\n",
      "   809740    2.623    0.000    2.623    0.000 {numpy.core.multiarray.zeros}\n",
      "   600144    1.776    0.000    3.090    0.000 linalg.py:139(_commonType)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats.sort_stats('time').print_stats(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "lstats = %lprun -r -f sampler sampler(X, 30, 0, sigmaX, sigmaA,alpha, N, D, maxNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigmaXZ=chain_Z[SAMPLE_SIZE-1,:,0:10].reshape(100,10)\n",
    "sigma_X=chain_sigma_X[SAMPLE_SIZE-1]\n",
    "sigma_A=chain_sigma_A[SAMPLE_SIZE-1]\n",
    "A_inf=np.dot(np.dot(np.linalg.inv((np.dot(Z.T,Z)+(sigma_X/sigma_A)*np.eye(4))),Z.T),X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(12,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(141)\n",
    "plt.pcolormesh(A_inf[0,:].reshape(6,6),cmap=plt.cm.gray)     \n",
    "plt.subplot(142)\n",
    "plt.pcolormesh(A_inf[1,:].reshape(6,6),cmap=plt.cm.gray)  \n",
    "plt.subplot(143)\n",
    "plt.pcolormesh(A_inf[2,:].reshape(6,6),cmap=plt.cm.gray)  \n",
    "plt.subplot(144)\n",
    "plt.pcolormesh(A_inf[3,:].reshape(6,6),cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(chain_K)\n",
    "#np.mean(chain_K)\n",
    "#np.sum(chain_K[200:999]==6)\n",
    "plt.hist(chain_K, bins = [4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(chain_alpha)\n",
    "np.mean(chain_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(chain_sigma_X)\n",
    "np.mean(chain_sigma_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(chain_sigma_A)\n",
    "np.mean(chain_sigma_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numbapro import cuda, vectorize, guvectorize, check_cuda\n",
    "from numbapro import void, uint8 , uint32, uint64, int32, int64, float32, float64, f8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available\n",
      "\n",
      "CUDA driver library cannot be found.\n",
      "If you are sure that a CUDA driver is installed,\n",
      "try setting environment variable NUMBAPRO_CUDA_DRIVER\n",
      "with the file path of the CUDA driver shared library.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numbapro\n",
    "numbapro.check_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if the code is working properly some of the unit testings I've come up with so far are:\n",
    "* Probabilities calculated for the presence of feature have to be between 0 and 1.\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
